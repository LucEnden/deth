{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Goal\n",
    "\n",
    "The goal of this experiment is to setup very minimalistic implementation of a battleing agent. This wil then function as a starting point for further development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import poke_battle_sim as pb\n",
    "import random\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import gymnasium as gym\n",
    "from typing import Optional\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "\n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data imports\n",
    "package_dir = str(os.sep).join(str(pb.poke_sim.__file__).split(os.sep)[0:-1])\n",
    "data_dir = os.path.join(package_dir, 'data')\n",
    "\n",
    "# Load dataframes\n",
    "abilities = pd.read_csv(os.path.join(data_dir, 'abilities.csv'))\n",
    "items_gen4 = pd.read_csv(os.path.join(data_dir, 'items_gen4.csv'))\n",
    "move_list = pd.read_csv(os.path.join(data_dir, 'move_list.csv'))\n",
    "natures = pd.read_csv(os.path.join(data_dir, 'natures.csv'))\n",
    "pokemon_stats = pd.read_csv(os.path.join(data_dir, 'pokemon_stats.csv'))\n",
    "# pokemon_stats.set_index('ndex', inplace=True)\n",
    "type_effectiveness = pd.read_csv(os.path.join(data_dir, 'type_effectiveness.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data helper methods\n",
    "def get_random_nature() -> str:\n",
    "    return random.choice(natures.values)[0]\n",
    "\n",
    "def get_stats_by_id(pokedex_id: int):\n",
    "    if pokedex_id < min(pokemon_stats['ndex']) or pokedex_id > max(pokemon_stats['ndex']):\n",
    "        raise ValueError(f'{pokedex_id} is not a valid pokedex id')\n",
    "    \n",
    "    return pb.PokeSim._pokemon_stats[pokedex_id - 1][4:10]\n",
    "\n",
    "def get_stats_by_name(name: str):\n",
    "    if name not in pokemon_stats['name'].values:\n",
    "        raise ValueError(f'{name} is not a valid pokemon name')\n",
    "    \n",
    "    search_results = [ i for i in pb.PokeSim._pokemon_stats if i[1] == name ] # TODO make this search more time efficient\n",
    "    if len(search_results) != 1:\n",
    "        raise ValueError(f'Invalid search results: expected 1, got {len(search_results)} while searching for {name}')\n",
    "\n",
    "    return search_results[0][4:10]\n",
    "\n",
    "def get_ability_id_by_name(name: str):\n",
    "    if name not in abilities['ability_name'].values:\n",
    "        raise ValueError(f'{name} is not a valid starter ability')\n",
    "\n",
    "    return abilities[abilities['ability_name'] == name]['ability_id'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding/Decoding methods\n",
    "# print(pb.conf.global_settings.POSSIBLE_GENDERS)\n",
    "gender_encoder = LabelEncoder()\n",
    "gender_encoder.fit(pb.conf.global_settings.POSSIBLE_GENDERS)\n",
    "\n",
    "def get_gender_encoding(gender: str):\n",
    "    return gender_encoder.transform([gender])[0]\n",
    "\n",
    "def get_gender_decoding(gender: int):\n",
    "    return gender_encoder.inverse_transform([gender])[0]\n",
    "\n",
    "def get_random_gender_mf():\n",
    "    return random.choice(['male', 'female'])\n",
    "\n",
    "type_encoder = LabelEncoder()\n",
    "type_encoder.fit(pokemon_stats[[ 'type 1', 'type 2' ]].values.flatten())\n",
    "\n",
    "def get_type_encoding(type_name: str | float):\n",
    "    if isinstance(type_name, float) and np.isnan(type_name):\n",
    "        return type_encoder.transform([np.nan])[0]\n",
    "    \n",
    "    if not type_name or type_name.lower() == 'none' or type_name.lower() == 'nan' or type_name == '':\n",
    "        return type_encoder.transform([np.nan])[0]\n",
    "    \n",
    "    return type_encoder.transform([type_name])[0]\n",
    "\n",
    "def get_type_decoding(type_id: int):\n",
    "    return type_encoder.inverse_transform([type_id])[0]\n",
    "\n",
    "def all_type_encodings():\n",
    "    return np.array(type_encoder.transform(type_encoder.classes_))\n",
    "\n",
    "# for c in type_encoder.classes_:\n",
    "#     print(f'{c} -> {get_type_encoding(c)} -> {get_type_decoding(get_type_encoding(c))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About the state space\n",
    "\n",
    "The starting point for the state space comes from the first rival battle in the game. The choice for this is to keep the state space as small as possible to make it easier to debug and understand the agent's behavior. It is also arguably the most interesting of starting points as this is the very first battle in the game. Making the state space any smaller would result in an agent that does not really learn to do anything of meaning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sizing the state space\n",
    "\n",
    "Alto the statespace seems small, it is still quite large. At first glance, all the state space is are 2 pokemons:\n",
    "> $ \\{ p1, p2 \\} $\n",
    "\n",
    "However, when we look into what each pokemon's attributes it becomes aperent how fast the state space grows. To make things easier, lets look at the pokemon showdown calculator to see what could be included in a battle state:\n",
    "\n",
    "![pokemon showdown calculator screenshot](showdown_calculator_screenshot.png)\n",
    "\n",
    "The calculator shows inputs for the current pokemons out in battle (so not the remaining party in the players parties). Every single input (be it buttons or text fields) in the calculator is a part of the state space. Note that not all inputs apply to all party members, for example, the buttons centered on the calculator (say Protect for example) only apply to the pokemon out in battle. Given the valid input space for each of these fields (base hp can range from 0 to a practical maximum of 150 for example), it becomse almost astronamicaly large. This large state space is what will dictate the approaches usable in this experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing an approach for the sized state space\n",
    "\n",
    "From this first glance I can already safely state that Q-Tabels are not a viable approach, as the tables would be to large to work with within a reasonable amount of time (for my computer at least). We could try to see which parts of the state space to scrap, which would be an interesting experiment. It might be nice to see wheter an agent could learn to battle, for example, without knowing anything about a pokemons attribute that dictate its stats (like base stats, IVs, EVs, etc) except perhaps its level. However I will be opting for different approache.\n",
    "\n",
    "I will be opting for a Deep Q-Learning approach (page 867 of the book). I might even try to implement Double Deep Q-Learning if the model overfits. Deep Q-Learning is an on-policy, model-free approach that uses a deep neural network to approximate the Q-function. This is a good approach for this experiment as it can handle large state spaces. Double Deep Q-Learning is the off-policy variant of Deep Q-Learning that uses two networks to prevent overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observation Space\n",
    "\n",
    "The observation space should include the following:\n",
    "- The agents party\n",
    "- That NPC's party\n",
    "- Stat changes from buffs and debuffs (like leer, growl, etc)\n",
    "\n",
    "A party consists of one to six Pokémon in the form of a dictionary, where the keys are the position of a Pokémon within the party (so key = 0 is the Pokémon in front of the party, key one the next Pokémon in the party etc).\n",
    "\n",
    "A Pokémon is a tuple with:\n",
    "- Stat totals (computed stats based on EV’s, IV’s, Base stats, Level and nature)\n",
    "- Types (one or two types)\n",
    "- Its ability\n",
    "- Available moves\n",
    "\n",
    "Some more notes on the observation space:\n",
    "- For the agent's party, all this information is known beforehand. \n",
    "- For the NPC's party, the agent will have to learn how to gather this information throughout every episode.\n",
    "\n",
    "To get these observations, we will first define it and then see how we can get it from the simulator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data on available pokemon in the starting battle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "starter_lvl = 5\n",
    "starter_names = ['turtwig', 'chimchar', 'piplup']\n",
    "starter_moves = {\n",
    "    'turtwig': ['tackle', 'withdraw'],\n",
    "    'chimchar': ['scratch', 'leer'],\n",
    "    'piplup': ['pound', 'growl']\n",
    "}\n",
    "starter_abilities = {\n",
    "    'turtwig': 'overgrow',\n",
    "    'chimchar': 'blaze',\n",
    "    'piplup': 'torrent'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_starter(name: str):\n",
    "    if name not in starter_names:\n",
    "        raise ValueError(f'{name} is not a valid starter name')\n",
    "    \n",
    "    stats = get_stats_by_name(name)\n",
    "\n",
    "    return pb.Pokemon(\n",
    "        name_or_id=name,\n",
    "        level=starter_lvl,\n",
    "        moves=starter_moves[name],\n",
    "        gender=get_random_gender_mf(),\n",
    "        ability=starter_abilities[name],\n",
    "        nature=get_random_nature(),\n",
    "        cur_hp=stats[0],\n",
    "        stats_actual=stats\n",
    "    )\n",
    "\n",
    "\n",
    "def get_random_starter():\n",
    "    name = random.choice(starter_names)\n",
    "    return get_starter(name)\n",
    "\n",
    "\n",
    "def get_rival_starter(agent_starter_name: str):\n",
    "    name = ''\n",
    "    if agent_starter_name == 'turtwig':\n",
    "        name = 'chimchar'\n",
    "    elif agent_starter_name == 'chimchar':\n",
    "        name = 'piplup'\n",
    "    elif agent_starter_name == 'piplup':\n",
    "        name = 'turtwig'\n",
    "\n",
    "    return get_starter(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random starter: piplup\n",
      "Rival starter: turtwig\n"
     ]
    }
   ],
   "source": [
    "starter_name = get_random_starter().name\n",
    "print(f'Random starter: {starter_name}')\n",
    "print(f'Rival starter: {get_rival_starter(starter_name).name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From data to observation space \n",
    "\n",
    "In order to turn the data we have at our disposal to the observation space, we will have to do the following:\n",
    "- See what [state spaces gym makes available](https://gymnasium.farama.org/api/spaces/fundamental/#fundamental-spaces) to us\n",
    "- See what the data looks like made available by the simulator\n",
    "- Translate the data to the available state spaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### About state spaces\n",
    "\n",
    "Statespaces all have numerical values so it seems, take the Discrete space for example: its essentially just a set of integers. The dictionary might have textual keys, but the values are all just other numerical spaces (or nested dictionaries). I will try and summerize the state space in terms of what they are and when to use them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fundamental Spaces:**\n",
    "> | Name          | Description                                      | When to Use                               |\n",
    "> |---------------|------------------------------------------------- |-------------------------------------------|\n",
    "> | Box           | Continuous space with bounds for each dimension. | For continuous values like positions.     |\n",
    "> | Discrete      | Finite range of non-negative integers.           | For finite actions or states.             |\n",
    "> | MultiBinary   | Binary space, each dimension is 0 or 1.          | For independent on/off states.            |\n",
    "> | MultiDiscrete | Multi-dimensional discrete ranges.               | For actions with separate finite options. |\n",
    "> | Text          | Space for text or character sequences.           | For tasks involving text input/output.    |\n",
    "\n",
    "**Composite Spaces:**\n",
    "> | Name     | Description                               | When to Use                                |\n",
    "> |----------|-------------------------------------------|--------------------------------------------|\n",
    "> | Dict     | Combines spaces as key-value pairs.       | For JSON-like structures.                  |\n",
    "> | Tuple    | Combines spaces by position.              | For ordered combinations like coordinates. |\n",
    "> | Sequence | Variable-length sequences of elements.    | For variable input/output, e.g., lists.    |\n",
    "> | Graph    | Represents nodes and edges with features. | For relational or graph data.              |\n",
    "> | OneOf    | Allows elements from multiple spaces.     | For mutually exclusive action types.       |\n",
    "\n",
    "**State utility functions:**\n",
    "> | Name            | Description                                       | When to Use                                 |\n",
    "> |-----------------|---------------------------------------------------|---------------------------------------------|\n",
    "> | flatten_space() | Converts composite space to a flat `Box`.         | For vectorizing complex spaces.             |\n",
    "> | flatten()       | Converts a space element into a vector.           | For preprocessing data into a flat form.    |\n",
    "> | flatdim()       | Gets the dimensionality of a flat space.          | For model input size or preprocessing.      |\n",
    "> | unflatten()     | Converts a vector back to the original structure. | For restoring structured data.              |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **EDITORS NOTE**\n",
    "\n",
    "I just found out that stabel baselines does not work very well with discrete state spaces that do not start with 0 (either negative or possitive). I was planning on reducing the state space size by making it so that the spaces are smaller, by starting them at the lowest possible value a stat can be. Unfortunatly, this is not possible with stabel baselines.\n",
    "\n",
    "Since I have been working on defining a environment for about a week now (of which most of the time went towards defining the state space), I am going to simplify my life by making the state space alot smaller. If you think about it, the only impact the agents actions have in the starter battle are 2 fold:\n",
    "- The agent can choose to attack, lowering the opponents health (and vice versa for the opponent)\n",
    "- The agent can choose to lower one of the opponents stats (and vice versa for the opponent)\n",
    "\n",
    "Thus I will be reducing the state space to just include the pokemon stats and the stat stages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pokemon stats\n",
    "\n",
    "It seems that the Discrete space is the most fitting for the stats of the pokemon. The stats are all integers, each stat having their own minimum and maximum value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ndex</th>\n",
       "      <th>name</th>\n",
       "      <th>type 1</th>\n",
       "      <th>type 2</th>\n",
       "      <th>hp</th>\n",
       "      <th>attack</th>\n",
       "      <th>defense</th>\n",
       "      <th>sp. atk</th>\n",
       "      <th>sp. def</th>\n",
       "      <th>speed</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>base exp.</th>\n",
       "      <th>gen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>387</td>\n",
       "      <td>turtwig</td>\n",
       "      <td>grass</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55</td>\n",
       "      <td>68</td>\n",
       "      <td>64</td>\n",
       "      <td>45</td>\n",
       "      <td>55</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>102</td>\n",
       "      <td>64</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>390</td>\n",
       "      <td>chimchar</td>\n",
       "      <td>fire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44</td>\n",
       "      <td>58</td>\n",
       "      <td>44</td>\n",
       "      <td>58</td>\n",
       "      <td>44</td>\n",
       "      <td>61</td>\n",
       "      <td>5</td>\n",
       "      <td>62</td>\n",
       "      <td>62</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>393</td>\n",
       "      <td>piplup</td>\n",
       "      <td>water</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53</td>\n",
       "      <td>51</td>\n",
       "      <td>53</td>\n",
       "      <td>61</td>\n",
       "      <td>56</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>52</td>\n",
       "      <td>63</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ndex      name type 1 type 2  hp  attack  defense  sp. atk  sp. def  \\\n",
       "386   387   turtwig  grass    NaN  55      68       64       45       55   \n",
       "389   390  chimchar   fire    NaN  44      58       44       58       44   \n",
       "392   393    piplup  water    NaN  53      51       53       61       56   \n",
       "\n",
       "     speed  height  weight  base exp.  gen  \n",
       "386     31       4     102         64    4  \n",
       "389     61       5      62         62    4  \n",
       "392     40       4      52         63    4  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "starter_df = pokemon_stats.copy()\n",
    "starter_df = starter_df[starter_df['name'].isin(starter_names)]\n",
    "starter_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_columns = ['hp', 'attack', 'defense', 'sp. atk', 'sp. def', 'speed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_space = gym.spaces.Discrete(starter_df['hp'].max() + 1)\n",
    "attack_space = gym.spaces.Discrete(starter_df['attack'].max() + 1)\n",
    "defense_space = gym.spaces.Discrete(starter_df['defense'].max() + 1)\n",
    "sp_atk_space = gym.spaces.Discrete(starter_df['sp. atk'].max() + 1)\n",
    "sp_def_space = gym.spaces.Discrete(starter_df['sp. def'].max() + 1)\n",
    "speed_space = gym.spaces.Discrete(starter_df['speed'].max() + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity checks\n",
    "_max = starter_df['hp'].max()\n",
    "assert all([ not hp_space.contains(-1), hp_space.contains(0), hp_space.contains(_max), not hp_space.contains(_max + 1) ])\n",
    "\n",
    "_max = starter_df['attack'].max()\n",
    "assert all([ not attack_space.contains(-1), attack_space.contains(0), attack_space.contains(_max), not attack_space.contains(_max + 1) ])\n",
    "\n",
    "_max = starter_df['defense'].max()\n",
    "assert all([ not defense_space.contains(-1), defense_space.contains(0), defense_space.contains(_max), not defense_space.contains(_max + 1) ])\n",
    "\n",
    "_max = starter_df['sp. atk'].max()\n",
    "assert all([ not sp_atk_space.contains(-1), sp_atk_space.contains(0), sp_atk_space.contains(_max), not sp_atk_space.contains(_max + 1) ])\n",
    "\n",
    "_max = starter_df['sp. def'].max()\n",
    "assert all([ not sp_def_space.contains(-1), sp_def_space.contains(0), sp_def_space.contains(_max), not sp_def_space.contains(_max + 1) ])\n",
    "\n",
    "_max = starter_df['speed'].max()\n",
    "assert all([ not speed_space.contains(-1), speed_space.contains(0), speed_space.contains(_max), not speed_space.contains(_max + 1) ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Volatile status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In `%ENV-DIR%/poke_battle_sim/poke_sim/core/pokemon.py::Pokemon::reset_stats()` we can see that for that pokemon instance, `self.stat_tages` is set to a list of ints. This prorty is not available once the pokemon is instantiated, as their is no refrence to it in the `__init__` method. The `reset_stats()` has a refrence in the `%ENV-DIR%/poke_battle_sim/poke_sim/util/process_move.py::_ef_050()` method. It seems that each effect ID from the `move_list` dataframe has its own method in this file. Lets look at the `ef_017` (the effect ID of growl and leer) method to see what it does. \n",
    "\n",
    "```py\n",
    "    if defender.is_alive and defender.trainer.mist:\n",
    "        battle.add_text(defender.nickname + \"'s protected by mist.\")\n",
    "        return True\n",
    "    give_stat_change(defender, battle, move_data.ef_stat, move_data.ef_amount)\n",
    "```\n",
    "\n",
    "It seems the `%ENV-DIR%/poke_battle_sim/poke_sim/util/process_move.py::give_stat_change()` method is used to apply stat changes. This in turn is used in `%ENV-DIR%/poke_battle_sim/poke_sim/core/pokemon.py::Battle` instance. This allows me to conclude that somewhere when the battle is started, the `stat_tages` property becomes available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "lucas = pb.Trainer('lucas', [get_random_starter()])\n",
    "barry = pb.Trainer('barry', [get_rival_starter(lucas.poke_list[0].name)])\n",
    "battle = pb.Battle(lucas, barry)\n",
    "battle.start()\n",
    "\n",
    "print(battle.t1.poke_list[0].stat_stages)\n",
    "print(battle.t2.poke_list[0].stat_stages)\n",
    "\n",
    "battle.turn(\n",
    "    t1_turn=['move', lucas.poke_list[0].moves[1].name],\n",
    "    t2_turn=['move', barry.poke_list[0].moves[1].name]\n",
    ")\n",
    "print(battle.t1.poke_list[0].stat_stages)\n",
    "print(battle.t2.poke_list[0].stat_stages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we know how to get this from the simulator, we need to define a statespace that can hold this information. The Discrete space seems to be the best fit for this. This is because all stat change stages are integers ranging from -6 to 6. In order to make the observation space work with stable baselines, we will have to map the stat stages to a range of 0 to 12 from -6 to 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_stage_space = gym.spaces.Discrete(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert all([ not stat_stage_space.contains(-1), stat_stage_space.contains(0), stat_stage_space.contains(12), not stat_stage_space.contains(13) ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_stat_stages(stat_stages: list[int]) -> np.ndarray:\n",
    "    if len(stat_stages) != 6:\n",
    "        raise ValueError('Expected exactly 6 stat stages')\n",
    "    \n",
    "    # map from -6 / 6 to 0 / 12\n",
    "    return np.array(stat_stages) + 6\n",
    "\n",
    "assert np.array_equal(map_stat_stages([0, 0, 0, 0, 0, 0]), np.array([6, 6, 6, 6, 6, 6]))\n",
    "assert np.array_equal(map_stat_stages([6, 6, 6, 6, 6, 6]), np.array([12, 12, 12, 12, 12, 12]))\n",
    "assert np.array_equal(map_stat_stages([-6, -6, -6, -6, -6, -6]), np.array([0, 0, 0, 0, 0, 0]))\n",
    "assert np.array_equal(map_stat_stages([-6, -4, -2, 2, 4, 6]), np.array([0, 2, 4, 8, 10, 12]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Move observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_starter_moves = np.array(list(starter_moves.values())).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>identifier</th>\n",
       "      <th>generation_id</th>\n",
       "      <th>type_id</th>\n",
       "      <th>power</th>\n",
       "      <th>pp</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>priority</th>\n",
       "      <th>target_id</th>\n",
       "      <th>move_class</th>\n",
       "      <th>effect_id</th>\n",
       "      <th>effect_chance</th>\n",
       "      <th>effect_amt</th>\n",
       "      <th>effect_stat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>pound</td>\n",
       "      <td>1</td>\n",
       "      <td>normal</td>\n",
       "      <td>40.0</td>\n",
       "      <td>35</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>scratch</td>\n",
       "      <td>1</td>\n",
       "      <td>normal</td>\n",
       "      <td>40.0</td>\n",
       "      <td>35</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>tackle</td>\n",
       "      <td>1</td>\n",
       "      <td>normal</td>\n",
       "      <td>40.0</td>\n",
       "      <td>35</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>43</td>\n",
       "      <td>leer</td>\n",
       "      <td>1</td>\n",
       "      <td>normal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>45</td>\n",
       "      <td>growl</td>\n",
       "      <td>1</td>\n",
       "      <td>normal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>110</td>\n",
       "      <td>withdraw</td>\n",
       "      <td>1</td>\n",
       "      <td>water</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id identifier  generation_id type_id  power  pp  accuracy  priority  \\\n",
       "0      1      pound              1  normal   40.0  35     100.0         0   \n",
       "9     10    scratch              1  normal   40.0  35     100.0         0   \n",
       "32    33     tackle              1  normal   40.0  35     100.0         0   \n",
       "42    43       leer              1  normal    NaN  30     100.0         0   \n",
       "44    45      growl              1  normal    NaN  40     100.0         0   \n",
       "109  110   withdraw              1   water    NaN  40       NaN         0   \n",
       "\n",
       "     target_id  move_class  effect_id  effect_chance  effect_amt  effect_stat  \n",
       "0           10           2          1            NaN         NaN          NaN  \n",
       "9           10           2          1            NaN         NaN          NaN  \n",
       "32          10           2          1            NaN         NaN          NaN  \n",
       "42          11           1         17            NaN        -1.0          2.0  \n",
       "44          11           1         17            NaN        -1.0          1.0  \n",
       "109          7           1         16            NaN         1.0          2.0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "move_list = move_list[move_list['identifier'].isin(all_starter_moves)]\n",
    "move_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following columns will be included in the observation space:\n",
    "- power\n",
    "- pp\n",
    "- target_id\n",
    "- move_class\n",
    "- effect_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_of_interest = ['power', 'pp', 'target_id', 'move_class', 'effect_id']\n",
    "move_list = move_list[columns_of_interest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>power</th>\n",
       "      <th>pp</th>\n",
       "      <th>target_id</th>\n",
       "      <th>move_class</th>\n",
       "      <th>effect_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.0</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>40.0</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>40.0</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>NaN</td>\n",
       "      <td>30</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>NaN</td>\n",
       "      <td>40</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>NaN</td>\n",
       "      <td>40</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     power  pp  target_id  move_class  effect_id\n",
       "0     40.0  35         10           2          1\n",
       "9     40.0  35         10           2          1\n",
       "32    40.0  35         10           2          1\n",
       "42     NaN  30         11           1         17\n",
       "44     NaN  40         11           1         17\n",
       "109    NaN  40          7           1         16"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "move_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luc\\AppData\\Local\\Temp\\ipykernel_1304176\\3785705825.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  move_list['power'].fillna(0, inplace=True)\n",
      "C:\\Users\\luc\\AppData\\Local\\Temp\\ipykernel_1304176\\3785705825.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  move_list['power'].fillna(0, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>power</th>\n",
       "      <th>pp</th>\n",
       "      <th>target_id</th>\n",
       "      <th>move_class</th>\n",
       "      <th>effect_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     power  pp  target_id  move_class  effect_id\n",
       "0       40  35         10           2          1\n",
       "9       40  35         10           2          1\n",
       "32      40  35         10           2          1\n",
       "42       0  30         11           1         17\n",
       "44       0  40         11           1         17\n",
       "109      0  40          7           1         16"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "move_list['power'].fillna(0, inplace=True)\n",
    "move_list = move_list.astype(int)\n",
    "move_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "move_power_space = gym.spaces.Discrete(move_list['power'].max() + 1)\n",
    "move_pp_space = gym.spaces.Discrete(move_list['pp'].max() + 1)\n",
    "move_target_space = gym.spaces.Discrete(move_list['target_id'].max() + 1)\n",
    "move_class_space = gym.spaces.Discrete(move_list['move_class'].max() + 1)\n",
    "move_effect_id_space = gym.spaces.Discrete(move_list['effect_id'].max() + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (False, True, True, False) == (\n",
    "    move_power_space.contains(-1), \n",
    "    move_power_space.contains(0), \n",
    "    move_power_space.contains(move_list['power'].max()), \n",
    "    move_power_space.contains(move_list['power'].max() + 1)\n",
    ")\n",
    "\n",
    "assert (False, True, True, False) == (\n",
    "    move_pp_space.contains(-1), \n",
    "    move_pp_space.contains(0), \n",
    "    move_pp_space.contains(move_list['pp'].max()), \n",
    "    move_pp_space.contains(move_list['pp'].max() + 1)\n",
    ")\n",
    "\n",
    "assert (False, True, True, False) == (\n",
    "    move_target_space.contains(-1), \n",
    "    move_target_space.contains(0), \n",
    "    move_target_space.contains(move_list['target_id'].max()), \n",
    "    move_target_space.contains(move_list['target_id'].max() + 1)\n",
    ")\n",
    "\n",
    "assert (False, True, True, False) == (\n",
    "    move_class_space.contains(-1), \n",
    "    move_class_space.contains(0), \n",
    "    move_class_space.contains(move_list['move_class'].max()), \n",
    "    move_class_space.contains(move_list['move_class'].max() + 1)\n",
    ")\n",
    "\n",
    "assert (False, True, True, False) == (\n",
    "    move_effect_id_space.contains(-1), \n",
    "    move_effect_id_space.contains(0), \n",
    "    move_effect_id_space.contains(move_list['effect_id'].max()), \n",
    "    move_effect_id_space.contains(move_list['effect_id'].max() + 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The empty move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_move = {\n",
    "    'power': 0,\n",
    "    'pp': 0,\n",
    "    'target_id': 0,\n",
    "    'move_class': 0,\n",
    "    'effect_id': 0\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OLD STATE SPACES (not included in starter battle environment)\n",
    "\n",
    "This chapter is purley for archival purposes to show my work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Typing\n",
    "\n",
    "Types are strings that we already have an encoded representation for. We can again use the Discrete space for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# typing_space = gym.spaces.Discrete(all_type_encodings().max() + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Sanity checks\n",
    "# assert not typing_space.contains(-1)\n",
    "# for i in type_encoder.classes_:\n",
    "#     assert typing_space.contains(get_type_encoding(i))\n",
    "# assert not typing_space.contains(18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Abilities\n",
    "\n",
    "It seems that we already have a numerical representation of the abilities. We can use the Discrete space for this as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# starter_abilities_df = abilities[abilities['ability_name'].isin(starter_abilities.values())]\n",
    "# starter_abilities_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min_max_ability = (starter_abilities_df['ability_id'].min(), starter_abilities_df['ability_id'].max() + 1 - starter_abilities_df['ability_id'].min())\n",
    "# ability_space = gym.spaces.Discrete(min_max_ability[1], start=min_max_ability[0])\n",
    "# ability_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ability_space = gym.spaces.Discrete(starter_abilities_df['ability_id'].max() + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert not ability_space.contains(-1)\n",
    "# assert ability_space.contains(starter_abilities_df['ability_id'].min())\n",
    "# assert ability_space.contains(starter_abilities_df['ability_id'].max())\n",
    "# assert not ability_space.contains(starter_abilities_df['ability_id'].max() + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Moves\n",
    "\n",
    "I would prefer if we could make each move a tuple for each individual move and have the values of the tuple be discrete spaces. First lets look at the columns of the moves dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# starter_moves_values = np.array(list(starter_moves.values())).flatten()\n",
    "# starter_move_list = move_list[move_list['identifier'].isin(starter_moves_values)].copy()\n",
    "# starter_move_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# starter_move_list.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### About the moves dataframe\n",
    "\n",
    "About these columns:\n",
    "- The `id` column we can drop as a move is essentially defined by other stats and its effect.\n",
    "- The `identifier` column we can drop as it is not needed for the agent.\n",
    "- The `generation_id` column we can drop as it is not needed for the agent.\n",
    "- The `type_id` we need to apply label encodeding (which should be easy).\n",
    "- The `power` column we can use as is, as it is a numerical value.\n",
    "  - The `np.nan` values we can replace with 0 for moves that do stat changes (leer, growl and withdraw).\n",
    "  - These stats being changed by these moves are dictated by the `effect_stat` column.\n",
    "- The `pp` column we can use as is, as it is a numerical value.\n",
    "- The `accuracy` column we can use as is, as it is a numerical value.\n",
    "  - The `np.nan` values we can replace with -1 for moves that are accuracy independent (like withdraw).\n",
    "- The `priority` column we can use as is, as it is a numerical value.\n",
    "- The `target_id` column we can use as is.\n",
    "  - The column describes what the move targets. \n",
    "  - A move that targets the users stats (like withdraw) or a move that targets the opponents HP (like tackle) for example all have a unique `target_id`.\n",
    "- The `move_class` column we can use as is.\n",
    "  - The column describes what kind of move it is (like physical, special or status).\n",
    "  - I thought label encoding would be needed, but it seems the column is already encoded (1 for status, 2 for physical and 3 for special).\n",
    "- The `effect_id` column we can use as is.\n",
    "  - The column describes what kind of effect the move has (like stat change, status effect or damage).\n",
    "  - It is essentially a label encoding for each unique effect, which is perfect!\n",
    "- The `effect_chance` column we can use as is.\n",
    "  - The column describes the chance of an extra effect happening, if any.\n",
    "  - We can replace the `np.nan` values with 0 for moves that have no effect (like tackle).\n",
    "- The `effect_amt` column we can use as is.\n",
    "  - The column describes the amount of the effect that happens, if any.\n",
    "  - It impact moves with a secondary effect such as stat changes (like with the move ominous wind).\n",
    "  - We can replace the `np.nan` values with 0 for moves that have no effect (like tackle).\n",
    "- The `effect_stat` column we can use as is.\n",
    "  - The column describes what stat the move changes, if any.\n",
    "  - We can replace the `np.nan` values with 0 for moves that deal direct damage (like tackle) to indicate it targets the HP stat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move_list[move_list['identifier'] == 'aerial-ace']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_case_accuracy = round(move_list['accuracy'].max() * (8/2) * 1.3 * 1.1 * 1.2 * 1.2 * (5/3))\n",
    "# worst_case_accuracy = round(max(move_list['accuracy'].min(), 1) * (2/8) * 0.8 * 0.8 * 0.6 * 0.8 * 0.5 * 0.9 * 0.9)\n",
    "\n",
    "# best_case_accuracy, worst_case_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move_list[move_list['accuracy'] <= 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# starter_move_list.drop(columns=['id', 'identifier', 'generation_id'], inplace=True)\n",
    "# starter_move_list['type_id'] = starter_move_list['type_id'].apply(lambda x: get_type_encoding(x))\n",
    "# # starter_move_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stat_change_effect_ids = [ 16, 17 ]\n",
    "# condition = starter_move_list['effect_id'].isin(stat_change_effect_ids)\n",
    "# starter_move_list.loc[condition, 'power'] = starter_move_list.loc[condition, 'power'].fillna(0)\n",
    "# # starter_move_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# effect_id_that_are_accuracy_independend = [ 16 ]\n",
    "# condition = starter_move_list['effect_id'].isin(effect_id_that_are_accuracy_independend)\n",
    "# starter_move_list.loc[condition, 'accuracy'] = starter_move_list.loc[condition, 'accuracy'].fillna(-1)\n",
    "# # starter_move_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# effect_id_that_have_no_secondary_effect = [ 1, 16, 17 ]\n",
    "# condition = starter_move_list['effect_id'].isin(effect_id_that_have_no_secondary_effect)\n",
    "# starter_move_list.loc[condition, 'effect_amt'] = starter_move_list.loc[condition, 'effect_amt'].fillna(0)\n",
    "# starter_move_list.loc[condition, 'effect_chance'] = starter_move_list.loc[condition, 'effect_chance'].fillna(0)\n",
    "# # starter_move_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# effect_id_that_deal_direct_damage = [ 1 ]\n",
    "# condition = starter_move_list['effect_id'].isin(effect_id_that_deal_direct_damage)\n",
    "# starter_move_list.loc[condition, 'effect_stat'] = starter_move_list.loc[condition, 'effect_stat'].fillna(0)\n",
    "# # starter_move_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# starter_move_list = starter_move_list.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Move data frame after above changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# starter_move_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# starter_move_list.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# starter_move_list.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### About the empty move\n",
    "\n",
    "It is important to think about the case where a pokemon has less then 4 moves. We could use splash as a placeholder move, as its a move that litteraly does nothing, but this would perhaps be missleading for the agent. \n",
    "\n",
    "**Important note:**\n",
    "> All these values need to be distinctly unique, as we can not have this empty move tuple be the same as any other move tuple. Otherwise it will negativly impact the agent's learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for c in starter_move_list.columns:\n",
    "#     print(c, starter_move_list[c].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The empty move will be defined as followed:\n",
    "> $\\lambda = (17, -1, -1, -1, 0, -1, -1, -1, -1, 0, -1)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty_move = {\n",
    "#     'type_id': get_type_encoding(np.nan),\n",
    "#     'power': -1,\n",
    "#     'pp': -1,\n",
    "#     'accuracy': -1,\n",
    "#     'priority': 0,\n",
    "#     'target_id': -1,\n",
    "#     'move_class': -1,\n",
    "#     'effect_id': -1,\n",
    "#     'effect_chance': -1,\n",
    "#     'effect_amt': 0,\n",
    "#     'effect_stat': -1\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# starter_move_list.loc[len(starter_move_list)] = empty_move\n",
    "# starter_move_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Moves as a tuple of Discrete spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# starter_move_list.drop(columns=['type_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# movecol_n_start = {}\n",
    "# for col in starter_move_list.columns:\n",
    "#     start = starter_move_list[col].min()\n",
    "#     n = starter_move_list[col].max() + 1 - start\n",
    "\n",
    "#     movecol_n_start[col] = (n, start)\n",
    "\n",
    "# movecol_n_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Type space is already defined\n",
    "# move_power_space = gym.spaces.Discrete(movecol_n_start['power'][0], start=movecol_n_start['power'][1])\n",
    "# move_pp_space = gym.spaces.Discrete(movecol_n_start['pp'][0], start=movecol_n_start['pp'][1])\n",
    "# move_accuracy_space = gym.spaces.Discrete(movecol_n_start['accuracy'][0], start=movecol_n_start['accuracy'][1])\n",
    "# move_priority_space = gym.spaces.Discrete(movecol_n_start['priority'][0], start=movecol_n_start['priority'][1])\n",
    "# move_target_space = gym.spaces.Discrete(movecol_n_start['target_id'][0], start=movecol_n_start['target_id'][1])\n",
    "# move_class_space = gym.spaces.Discrete(movecol_n_start['move_class'][0], start=movecol_n_start['move_class'][1])\n",
    "# move_effect_id_space = gym.spaces.Discrete(movecol_n_start['effect_id'][0], start=movecol_n_start['effect_id'][1])\n",
    "# move_effect_chance_space = gym.spaces.Discrete(movecol_n_start['effect_chance'][0], start=movecol_n_start['effect_chance'][1])\n",
    "# move_effect_amt_space = gym.spaces.Discrete(movecol_n_start['effect_amt'][0], start=movecol_n_start['effect_amt'][1])\n",
    "# move_effect_stat_space = gym.spaces.Discrete(movecol_n_start['effect_stat'][0], start=movecol_n_start['effect_stat'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Sanity checks\n",
    "# print(\n",
    "#     move_power_space.contains(starter_move_list['power'].min() - 1), \n",
    "#     move_power_space.contains(starter_move_list['power'].min()), \n",
    "#     move_power_space.contains(starter_move_list['power'].max()), \n",
    "#     move_power_space.contains(starter_move_list['power'].max() + 1)\n",
    "# )\n",
    "\n",
    "# print(\n",
    "#     move_pp_space.contains(starter_move_list['pp'].min() - 1), \n",
    "#     move_pp_space.contains(starter_move_list['pp'].min()), \n",
    "#     move_pp_space.contains(starter_move_list['pp'].max()), \n",
    "#     move_pp_space.contains(starter_move_list['pp'].max() + 1)\n",
    "# )\n",
    "\n",
    "# print(\n",
    "#     move_accuracy_space.contains(starter_move_list['accuracy'].min() - 1), \n",
    "#     move_accuracy_space.contains(starter_move_list['accuracy'].min()), \n",
    "#     move_accuracy_space.contains(starter_move_list['accuracy'].max()), \n",
    "#     move_accuracy_space.contains(starter_move_list['accuracy'].max() + 1)\n",
    "# )\n",
    "\n",
    "# print(\n",
    "#     move_priority_space.contains(starter_move_list['priority'].min() - 1), \n",
    "#     move_priority_space.contains(starter_move_list['priority'].min()), \n",
    "#     move_priority_space.contains(starter_move_list['priority'].max()), \n",
    "#     move_priority_space.contains(starter_move_list['priority'].max() + 1)\n",
    "# )\n",
    "\n",
    "# print(\n",
    "#     move_target_space.contains(starter_move_list['target_id'].min() - 1), \n",
    "#     move_target_space.contains(starter_move_list['target_id'].min()), \n",
    "#     move_target_space.contains(starter_move_list['target_id'].max()), \n",
    "#     move_target_space.contains(starter_move_list['target_id'].max() + 1)\n",
    "# )\n",
    "\n",
    "# print(\n",
    "#     move_class_space.contains(starter_move_list['move_class'].min() - 1), \n",
    "#     move_class_space.contains(starter_move_list['move_class'].min()), \n",
    "#     move_class_space.contains(starter_move_list['move_class'].max()), \n",
    "#     move_class_space.contains(starter_move_list['move_class'].max() + 1)\n",
    "# )\n",
    "\n",
    "# print(\n",
    "#     move_effect_id_space.contains(starter_move_list['effect_id'].min() - 1), \n",
    "#     move_effect_id_space.contains(starter_move_list['effect_id'].min()), \n",
    "#     move_effect_id_space.contains(starter_move_list['effect_id'].max()), \n",
    "#     move_effect_id_space.contains(starter_move_list['effect_id'].max() + 1)\n",
    "# )\n",
    "\n",
    "# print(\n",
    "#     move_effect_chance_space.contains(starter_move_list['effect_chance'].min() - 1), \n",
    "#     move_effect_chance_space.contains(starter_move_list['effect_chance'].min()), \n",
    "#     move_effect_chance_space.contains(starter_move_list['effect_chance'].max()), \n",
    "#     move_effect_chance_space.contains(starter_move_list['effect_chance'].max() + 1)\n",
    "# )\n",
    "\n",
    "# print(\n",
    "#     move_effect_amt_space.contains(starter_move_list['effect_amt'].min() - 1), \n",
    "#     move_effect_amt_space.contains(starter_move_list['effect_amt'].min()), \n",
    "#     move_effect_amt_space.contains(starter_move_list['effect_amt'].max()), \n",
    "#     move_effect_amt_space.contains(starter_move_list['effect_amt'].max() + 1)\n",
    "# )\n",
    "\n",
    "# print(\n",
    "#     move_effect_stat_space.contains(starter_move_list['effect_stat'].min() - 1), \n",
    "#     move_effect_stat_space.contains(starter_move_list['effect_stat'].min()), \n",
    "#     move_effect_stat_space.contains(starter_move_list['effect_stat'].max()), \n",
    "#     move_effect_stat_space.contains(starter_move_list['effect_stat'].max() + 1)\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 2 spaces commented out are the ones that, specifically for the starter pokemons, are always 0, making them redundant. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move_space = gym.spaces.Tuple([\n",
    "#     typing_space,\n",
    "#     move_power_space,\n",
    "#     move_pp_space,\n",
    "#     move_accuracy_space,\n",
    "#     # move_priority_space,\n",
    "#     move_target_space,\n",
    "#     move_class_space,\n",
    "#     move_effect_id_space,\n",
    "#     # move_effect_chance_space,\n",
    "#     move_effect_amt_space,\n",
    "#     move_effect_stat_space\n",
    "# ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now for the pokemon tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pokemon_space = gym.spaces.Tuple([\n",
    "#     hp_space,\n",
    "#     attack_space,\n",
    "#     defense_space,\n",
    "#     sp_atk_space,\n",
    "#     sp_def_space,\n",
    "#     speed_space,\n",
    "#     typing_space,\n",
    "#     typing_space,\n",
    "#     ability_space,\n",
    "#     move_space,\n",
    "#     move_space,\n",
    "#     move_space,\n",
    "#     move_space\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Manual space size calculation\n",
    "# space_size = 0\n",
    "# for space in pokemon_space:\n",
    "#     if isinstance(space, gym.spaces.Discrete):\n",
    "#         space_size += len(range(space.start, space.n))\n",
    "#     elif isinstance(space, gym.spaces.Tuple):\n",
    "#         for s in space:\n",
    "#             space_size += len(range(s.start, s.n))\n",
    "\n",
    "# print(space_size)\n",
    "\n",
    "# # Recursive space size calculation\n",
    "# def recursive_space_size(space: gym.spaces.Space, size: int = 0):\n",
    "#     if isinstance(space, gym.spaces.Discrete):\n",
    "#         size += len(range(space.start, space.n))\n",
    "#     elif isinstance(space, gym.spaces.Tuple):\n",
    "#         for s in space:\n",
    "#             size = recursive_space_size(s, size)\n",
    "\n",
    "#     return size\n",
    "\n",
    "# print(recursive_space_size(pokemon_space))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### And finally the party tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# party_space = gym.spaces.Tuple([\n",
    "#     pokemon_space,\n",
    "#     pokemon_space,\n",
    "#     pokemon_space,\n",
    "#     pokemon_space,\n",
    "#     pokemon_space,\n",
    "#     pokemon_space\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recursive_space_size(party_space) # 6 * 1022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Action Space\n",
    "\n",
    "The complete action space for the agent is defined by the set of buttons that can be pressed on the controller. These include the arrow keys (`up`, `down`, `left`, `right`), `A`, `B`, `L`, `R`, `X`, `Y`, `start`, and `select`. This will be referred to as the **fundamental action space**.\n",
    "\n",
    "Utilizing the fundamental action space directly may be unmeaningful due to its granularity and lack of abstraction. Instead, I define a **derived action space** that represents higher-level, semantically meaningful actions. These actions are constructed by combining or sequencing fundamental actions to achieve specific in-game outcomes. More specically, the dericed action space will include the following actions:\n",
    "- `switch`: Switch the active pokemon.\n",
    "- `move`: Use a move.\n",
    "- `item`: Use an item.\n",
    "\n",
    "**HOWEVER**, in the starter battle the agent will only be able to use the `move` action. The `item` and `switch` actions will be added in later experiments.\n",
    "\n",
    "Luckily, the `poke-battle-sim` supports the use of these derived actions!\n",
    "\n",
    "> From `%ENV-DIR%/Lib/site-packages/poke_battle_sim/core/battle.py::Battle::turn`:\n",
    "> ```python\n",
    "> \"\"\"\n",
    "> The three types of valid actions are:\n",
    "> 1. Moves - formatted as ['move', $move_name]\n",
    "> 2. Items - formatted as ['item', $item, $item_target_pos, $move_target_name?]\n",
    "> 3. Switch-out - formatted as ['other', 'switch']\n",
    "> \"\"\"\n",
    "> ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reward Function\n",
    "\n",
    "The initial reward function will be quite simplistic. The agent will be rewarded for winning a battle and penalized for losing a battle. The rewards and penalties will be kept small to prevent the agent from learning to exploit the reward function.\n",
    "\n",
    "| State Description | Reward Associated with reaching this state |\n",
    "|-------------------|--------------------------------------------|\n",
    "| Win | +1 |\n",
    "| Lose | -1 |\n",
    "| Non terminating state | -0.01 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On future reward shaping\n",
    "\n",
    "It might be good to research how to make the reward function follow a behaviour that takes into account different party sizes. For example: should the reward of winning a 6v6 battle be higher, less then or equal to winning a 1v1 battle? This question will be explored in later experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Important: Destroy any battle object before creating a new one\n",
    "lucas = None\n",
    "barry = None\n",
    "battle = None\n",
    "\n",
    "class StarterBattleEnvironment(gym.Env):\n",
    "    def __init__(self):\n",
    "        self._lucas = pb.Trainer('lucas', [get_random_starter()])\n",
    "        self._barry = pb.Trainer(\n",
    "            'barry', [get_rival_starter(self._lucas.poke_list[0].name)])\n",
    "        self._battle = pb.Battle(self._lucas, self._barry)\n",
    "        self._battle.start()\n",
    "\n",
    "        # Action mappings, formated as:\n",
    "        #   action_id: (action_type, pokemon_id, move_id)'\n",
    "        # Where:\n",
    "        #   action_type is one of 'move', 'switch', 'item'\n",
    "        #   pokemon_id is always 0 (for targetting the pokemon in the first party slot)\n",
    "        #   move_id is the index of the move in the pokemon's move list\n",
    "        self._action_mappings = {\n",
    "            0: ('move', 0, 0),\n",
    "            1: ('move', 0, 1),\n",
    "        }\n",
    "        self.action_space = gym.spaces.Discrete(len(self._action_mappings))\n",
    "\n",
    "        # Observation Space\n",
    "        self.observation_space = gym.spaces.Dict()\n",
    "        self.observation_prefixes = [ 'agent', 'npc' ]\n",
    "        for prefix in self.observation_prefixes:\n",
    "            for pokemon in range(1, 2):\n",
    "                self.observation_space[f\"{prefix}_pokemon{pokemon}_hp\"] = hp_space\n",
    "                self.observation_space[f\"{prefix}_pokemon{pokemon}_attack\"] = attack_space\n",
    "                self.observation_space[f\"{prefix}_pokemon{pokemon}_defense\"] = defense_space\n",
    "                self.observation_space[f\"{prefix}_pokemon{pokemon}_sp_atk\"] = sp_atk_space\n",
    "                self.observation_space[f\"{prefix}_pokemon{pokemon}_sp_def\"] = sp_def_space\n",
    "                self.observation_space[f\"{prefix}_pokemon{pokemon}_speed\"] = speed_space\n",
    "\n",
    "                for move in range(1, 3):\n",
    "                    self.observation_space[f\"{prefix}_pokemon{pokemon}_move{move}_power\"] = move_power_space\n",
    "                    self.observation_space[f\"{prefix}_pokemon{pokemon}_move{move}_pp\"] = move_pp_space\n",
    "                    self.observation_space[f\"{prefix}_pokemon{pokemon}_move{move}_target\"] = move_target_space\n",
    "                    self.observation_space[f\"{prefix}_pokemon{pokemon}_move{move}_class\"] = move_class_space\n",
    "                    self.observation_space[f\"{prefix}_pokemon{pokemon}_move{move}_effect_id\"] = move_effect_id_space\n",
    "\n",
    "            self.observation_space[f\"{prefix}_stat_stage_attack\"] = stat_stage_space\n",
    "            self.observation_space[f\"{prefix}_stat_stage_defense\"] = stat_stage_space\n",
    "            self.observation_space[f\"{prefix}_stat_stage_sp_atk\"] = stat_stage_space\n",
    "            self.observation_space[f\"{prefix}_stat_stage_sp_def\"] = stat_stage_space\n",
    "            self.observation_space[f\"{prefix}_stat_stage_speed\"] = stat_stage_space\n",
    "    \n",
    "    def _get_obs(self):\n",
    "        obs = {}\n",
    "        for prefix, trainer in zip(self.observation_prefixes, [self._battle.t1, self._battle.t2]):\n",
    "            for pokemon in range(1, 2):\n",
    "                p = trainer.poke_list[pokemon - 1]\n",
    "                obs[f\"{prefix}_pokemon{pokemon}_hp\"] = p.cur_hp\n",
    "                obs[f\"{prefix}_pokemon{pokemon}_attack\"] = p.base[1]\n",
    "                obs[f\"{prefix}_pokemon{pokemon}_defense\"] = p.base[2]\n",
    "                obs[f\"{prefix}_pokemon{pokemon}_sp_atk\"] = p.base[3]\n",
    "                obs[f\"{prefix}_pokemon{pokemon}_sp_def\"] = p.base[4]\n",
    "                obs[f\"{prefix}_pokemon{pokemon}_speed\"] = p.base[5]\n",
    "\n",
    "                for move in range(1, 3):\n",
    "                    m = p.moves[move - 1]\n",
    "                    obs[f\"{prefix}_pokemon{pokemon}_move{move}_power\"] = m.power if m.power else empty_move['power']\n",
    "                    obs[f\"{prefix}_pokemon{pokemon}_move{move}_pp\"] = m.current_pp if m.current_pp else empty_move['pp']\n",
    "                    obs[f\"{prefix}_pokemon{pokemon}_move{move}_target\"] = m.target if m.target else empty_move['target_id']\n",
    "                    obs[f\"{prefix}_pokemon{pokemon}_move{move}_class\"] = m.category if m.category else empty_move['move_class']\n",
    "                    obs[f\"{prefix}_pokemon{pokemon}_move{move}_effect_id\"] = m.ef_id if m.ef_id else empty_move['effect_id']\n",
    "\n",
    "            stat_stages = map_stat_stages(trainer.poke_list[0].stat_stages)\n",
    "            obs[f\"{prefix}_stat_stage_attack\"] = stat_stages[1]\n",
    "            obs[f\"{prefix}_stat_stage_defense\"] = stat_stages[2]\n",
    "            obs[f\"{prefix}_stat_stage_sp_atk\"] = stat_stages[3]\n",
    "            obs[f\"{prefix}_stat_stage_sp_def\"] = stat_stages[4]\n",
    "            obs[f\"{prefix}_stat_stage_speed\"] = stat_stages[5]\n",
    "\n",
    "        return obs\n",
    "\n",
    "    def _get_info(self):\n",
    "        return {\n",
    "            't1_pokemons': [p.name for p in self._battle.t1.poke_list],\n",
    "            't2_pokemons': [p.name for p in self._battle.t2.poke_list],\n",
    "        }\n",
    "    \n",
    "    def _reward(self):\n",
    "        if self._battle.get_winner() == self._lucas:\n",
    "            return 1\n",
    "        elif self._battle.get_winner() == self._barry:\n",
    "            return -1\n",
    "        \n",
    "        return -0.01  # Time penalty\n",
    "\n",
    "    def step(self, action):\n",
    "        if self._battle.is_finished():\n",
    "            raise ValueError('Cannot perform action in a finished battle')\n",
    "        \n",
    "        # Perform the action\n",
    "        action_type, pokemon_id, move_id = self._action_mappings[action]\n",
    "\n",
    "        # Punish heavily for invalid actions        \n",
    "        if not self._battle.t1.is_valid_action([action_type, self._battle.t1.poke_list[pokemon_id].moves[move_id].name]):\n",
    "            reward = -2\n",
    "        else: # Move is valid\n",
    "            self._battle.turn(\n",
    "                t1_turn=[\n",
    "                    action_type,\n",
    "                    self._battle.t1.poke_list[pokemon_id].moves[move_id].name\n",
    "                ],\n",
    "                t2_turn=[\n",
    "                    \"move\",\n",
    "                    random.choice(\n",
    "                        list(filter(\n",
    "                            lambda x: self._battle.t2.is_valid_action(\n",
    "                                [\"move\", x.name]\n",
    "                            ),\n",
    "                            self._battle.t2.current_poke.moves\n",
    "                        ))\n",
    "                    ).name\n",
    "                ]\n",
    "            )\n",
    "            reward = self._reward()\n",
    "\n",
    "        # TODO implement if statement for the following:\n",
    "        # - using a item the trainer does not have access to\n",
    "        # - switching to a fainted pokemon\n",
    "\n",
    "        observation = self._get_obs()\n",
    "        terminated = self._battle.winner is not None\n",
    "        truncated = False\n",
    "        info = self._get_info()\n",
    "\n",
    "        return observation, reward, terminated, truncated, info\n",
    "\n",
    "    def reset(self, seed: Optional[int] = None, options: Optional[dict] = None):\n",
    "        # We need the following line to seed self.np_random\n",
    "        super().reset(seed=seed)\n",
    "\n",
    "        # Reset the battle simulation\n",
    "        self._lucas = None\n",
    "        self._barry = None\n",
    "        self._battle = None\n",
    "\n",
    "        self._lucas = pb.Trainer('lucas', [get_random_starter()])\n",
    "        self._barry = pb.Trainer(\n",
    "            'barry', [get_rival_starter(self._lucas.poke_list[0].name)])\n",
    "        self._battle = pb.Battle(self._lucas, self._barry)\n",
    "        self._battle.start()\n",
    "\n",
    "        return self._get_obs(), self._get_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = StarterBattleEnvironment()\n",
    "check_env(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = StarterBattleEnvironment()\n",
    "obs, info = StarterBattleEnvironment().reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'agent_pokemon1_hp': 55,\n",
       " 'agent_pokemon1_attack': 68,\n",
       " 'agent_pokemon1_defense': 64,\n",
       " 'agent_pokemon1_sp_atk': 45,\n",
       " 'agent_pokemon1_sp_def': 55,\n",
       " 'agent_pokemon1_speed': 31,\n",
       " 'agent_pokemon1_move1_power': 40,\n",
       " 'agent_pokemon1_move1_pp': 35,\n",
       " 'agent_pokemon1_move1_target': 10,\n",
       " 'agent_pokemon1_move1_class': 2,\n",
       " 'agent_pokemon1_move1_effect_id': 1,\n",
       " 'agent_pokemon1_move2_power': 0,\n",
       " 'agent_pokemon1_move2_pp': 40,\n",
       " 'agent_pokemon1_move2_target': 7,\n",
       " 'agent_pokemon1_move2_class': 1,\n",
       " 'agent_pokemon1_move2_effect_id': 16,\n",
       " 'agent_stat_stage_attack': 6,\n",
       " 'agent_stat_stage_defense': 6,\n",
       " 'agent_stat_stage_sp_atk': 6,\n",
       " 'agent_stat_stage_sp_def': 6,\n",
       " 'agent_stat_stage_speed': 6,\n",
       " 'npc_pokemon1_hp': 44,\n",
       " 'npc_pokemon1_attack': 58,\n",
       " 'npc_pokemon1_defense': 44,\n",
       " 'npc_pokemon1_sp_atk': 58,\n",
       " 'npc_pokemon1_sp_def': 44,\n",
       " 'npc_pokemon1_speed': 61,\n",
       " 'npc_pokemon1_move1_power': 40,\n",
       " 'npc_pokemon1_move1_pp': 35,\n",
       " 'npc_pokemon1_move1_target': 10,\n",
       " 'npc_pokemon1_move1_class': 2,\n",
       " 'npc_pokemon1_move1_effect_id': 1,\n",
       " 'npc_pokemon1_move2_power': 0,\n",
       " 'npc_pokemon1_move2_pp': 30,\n",
       " 'npc_pokemon1_move2_target': 11,\n",
       " 'npc_pokemon1_move2_class': 1,\n",
       " 'npc_pokemon1_move2_effect_id': 17,\n",
       " 'npc_stat_stage_attack': 6,\n",
       " 'npc_stat_stage_defense': 6,\n",
       " 'npc_stat_stage_sp_atk': 6,\n",
       " 'npc_stat_stage_sp_def': 6,\n",
       " 'npc_stat_stage_speed': 6}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "assert all([ i[0] == i[1] for i in zip(obs.keys(), env.observation_space.spaces.keys()) ])\n",
    "assert len(obs) == len(env.observation_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 0.0019996166229248047 seconds\n",
      "Battle log:\n",
      "lucas sent out CHIMCHAR! barry sent out PIPLUP! \n",
      "Turn 1: CHIMCHAR used Leer! PIPLUP's Defense fell! PIPLUP used Growl! CHIMCHAR's Attack fell! \n",
      "Turn 2: CHIMCHAR used Scratch! PIPLUP used Pound! \n",
      "Turn 3: CHIMCHAR used Leer! PIPLUP's Defense fell! PIPLUP used Growl! CHIMCHAR's Attack fell! \n",
      "Turn 4: CHIMCHAR used Scratch! PIPLUP used Pound! \n",
      "Turn 5: CHIMCHAR used Leer! PIPLUP's Defense fell! PIPLUP used Pound! \n",
      "Turn 6: CHIMCHAR used Leer! PIPLUP's Defense fell! PIPLUP used Pound! \n",
      "Turn 7: CHIMCHAR used Leer! PIPLUP's Defense fell! PIPLUP used Pound! \n",
      "Turn 8: CHIMCHAR used Leer! PIPLUP's Defense won't go any lower! PIPLUP used Growl! CHIMCHAR's Attack fell! \n",
      "Turn 9: CHIMCHAR used Scratch! PIPLUP used Growl! CHIMCHAR's Attack fell! \n",
      "Turn 10: CHIMCHAR used Leer! PIPLUP used Growl! CHIMCHAR's Attack fell! \n",
      "Turn 11: CHIMCHAR used Leer! PIPLUP used Pound! \n",
      "Turn 12: CHIMCHAR used Leer! PIPLUP used Pound! \n",
      "Turn 13: CHIMCHAR used Leer! PIPLUP used Growl! CHIMCHAR's Attack won't go any lower! \n",
      "Turn 14: CHIMCHAR used Scratch! PIPLUP used Pound! \n",
      "Turn 15: CHIMCHAR used Leer! PIPLUP used Pound! CHIMCHAR fainted! barry has defeated lucas! \n"
     ]
    }
   ],
   "source": [
    "done = False\n",
    "start = time.time()\n",
    "max_time = 1 # seconds\n",
    "\n",
    "obs, _ = env.reset()\n",
    "while not done:\n",
    "    action = env.action_space.sample()\n",
    "    obs, reward, terminated, truncated, info = env.step(action)\n",
    "    done = terminated or truncated or (time.time() - start > max_time)\n",
    "end = time.time()\n",
    "\n",
    "print(f'Time taken: {end - start} seconds')\n",
    "print('Battle log:')\n",
    "cur_txt_parsed = \"\"\n",
    "for line in env._battle.cur_text:\n",
    "    if re.match(r'Turn \\d+:', line):\n",
    "        cur_txt_parsed += '\\n'\n",
    "    cur_txt_parsed += line\n",
    "    cur_txt_parsed += ' '\n",
    "print(cur_txt_parsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Policy\n",
    "\n",
    "For this starter battle environment I will be starting out by using an epsilon greedy policy. This is chosen as it is a simple policy that is easy to implement and understand. The epsilon greedy policy is a policy that selects the best action with a probability of $1 - \\epsilon$ and a random action with a probability of $\\epsilon$. This allows the agent to explore the environment while still exploiting the best actions it has learned.\n",
    "\n",
    "If epslin greedy yields poor results, I will switch to an epsilon decay policy. This policy is similar to the epsilon greedy policy, but the epsilon value decays over time. This allows the agent to explore more in the beginning and exploit more towards the end of training.\n",
    "\n",
    "<!-- \n",
    "- Eplsion greedy for starter battle\n",
    "- Eplsion greedy compared with Boltzmann exploration for future battles \n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasePolicy:\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "\n",
    "    def action(self, action: np.ndarray) -> int:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def update(self, step: int) -> None:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def config(self) -> dict:\n",
    "        d = {k: v for k, v in self.__dict__.items() if not k.startswith('_') and not callable(v)}\n",
    "        d['type'] = self.__class__.__name__\n",
    "        return d\n",
    "    \n",
    "class EpsilonGreedy(BasePolicy):\n",
    "    def __init__(self, epsilon: float, n_actions: int) -> None:\n",
    "        self.epsilon = epsilon\n",
    "        self.n_actions = n_actions\n",
    "\n",
    "    def action(self, q_values: np.ndarray) -> int:\n",
    "        if np.random.random() < self.epsilon:\n",
    "            return np.random.randint(self.n_actions)\n",
    "        else:\n",
    "            return np.argmax(q_values)\n",
    "        \n",
    "    def update(self, step: int) -> None:\n",
    "        pass\n",
    "\n",
    "class EpsilonDecay(BasePolicy):\n",
    "    def __init__(self, epsilon: float, _min: float, decay_rate: float, n_actions: int) -> None:\n",
    "        self.epsilon_init = epsilon\n",
    "        self.epsilon_current = epsilon\n",
    "        self.epsilon_min = _min\n",
    "        self.decay_rate = decay_rate\n",
    "        self.n_actions = n_actions\n",
    "\n",
    "    def action(self, q_values: np.ndarray) -> int:\n",
    "        if np.random.random() < self.epsilon_current:\n",
    "            return np.random.randint(self.n_actions)\n",
    "        else:\n",
    "            return np.argmax(q_values)\n",
    "\n",
    "    def update(self, step: int) -> None:\n",
    "        self.epsilon_current = max(\n",
    "            self.epsilon_current * (self.decay_rate ** step),\n",
    "            self.epsilon_min\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logging data for analysis\n",
    "\n",
    "The rewards will be logged over time to see potential exploitations of the reward function.\n",
    "\n",
    "Logging:\n",
    "- Cumuliative reward (must have)\n",
    "  - Should rise over time\n",
    "  - Should become less volatile over time\n",
    "- Every N percent, do a test run (must have)\n",
    "  - Do a battle\n",
    "  - Log the battle text\n",
    "  - Log the battle outcome\n",
    "- Log how much of the state space has been explored by the agent (should have)\n",
    "- Log how the agents decision making changes over time (quite advanded, could have)\n",
    "- Loss over time (should have)\n",
    "- Exploration (e.g., epsilon value) over time (should have)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_dir = os.path.abspath('./initial_pokemon_battleing_agent')\n",
    "if not os.path.exists(tensorboard_dir):\n",
    "    os.makedirs(tensorboard_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Free Approach (Deep Q-Learning)\n",
    "\n",
    "Architecture: Decide on the architecture of your Q-network. For example:\n",
    "- Fully connected layers for small, discrete state spaces.\n",
    "- Convolutional layers if your state is represented as images (e.g., screenshots of the game).\n",
    "\n",
    "Output: Ensure the network outputs a value for each action in the action space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Users\\luc\\anaconda3\\envs\\deth\\Lib\\site-packages\\stable_baselines3\\common\\buffers.py:605: UserWarning: This system does not have apparently enough memory to store the complete replay buffer 0.69GB > 0.01GB\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "env = StarterBattleEnvironment()\n",
    "model = DQN(\n",
    "    'MultiInputPolicy',\n",
    "    env,\n",
    "    verbose=1,\n",
    "    tensorboard_log=tensorboard_dir,\n",
    "    exploration_fraction=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunatly, the DQN model does not accept a custom policy. This means that the epsilon greedy policy will not be used in this approach. In future experiments, I will be looking into making a custom model with a custom policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_timesteps = 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "should_learn = False # Set to True to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "if should_learn:\n",
    "    model.learn(\n",
    "        total_timesteps=total_timesteps,\n",
    "        tb_log_name='dqn_starter_battle',\n",
    "    )\n",
    "    \n",
    "    model_name = f'dqn_starter_battle_{len(os.listdir(tensorboard_dir))}'\n",
    "    model_path = os.path.join(tensorboard_dir, model_name)\n",
    "    if not os.path.isfile(model_path):\n",
    "        model.save(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference on latest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Users\\luc\\anaconda3\\envs\\deth\\Lib\\site-packages\\stable_baselines3\\common\\buffers.py:605: UserWarning: This system does not have apparently enough memory to store the complete replay buffer 0.69GB > 0.02GB\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "env = StarterBattleEnvironment()\n",
    "model_path = os.path.join(tensorboard_dir, [ i for i in os.listdir(tensorboard_dir) if i.endswith('.zip') ][-1])\n",
    "model = DQN.load(model_path, env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 0.04630303382873535 seconds\n",
      "Total rewards: 0.86\n",
      "Battle log:\n",
      "lucas sent out CHIMCHAR! barry sent out PIPLUP! \n",
      "Turn 1: CHIMCHAR used Leer! PIPLUP's Defense fell! PIPLUP used Pound! \n",
      "Turn 2: CHIMCHAR used Leer! PIPLUP's Defense fell! PIPLUP used Growl! CHIMCHAR's Attack fell! \n",
      "Turn 3: CHIMCHAR used Leer! PIPLUP's Defense fell! PIPLUP used Pound! \n",
      "Turn 4: CHIMCHAR used Scratch! PIPLUP used Growl! CHIMCHAR's Attack fell! \n",
      "Turn 5: CHIMCHAR used Scratch! PIPLUP used Pound! \n",
      "Turn 6: CHIMCHAR used Scratch! PIPLUP used Growl! CHIMCHAR's Attack fell! \n",
      "Turn 7: CHIMCHAR used Scratch! PIPLUP used Pound! \n",
      "Turn 8: CHIMCHAR used Scratch! PIPLUP used Pound! \n",
      "Turn 9: CHIMCHAR used Scratch! PIPLUP used Growl! CHIMCHAR's Attack fell! \n",
      "Turn 10: CHIMCHAR used Scratch! PIPLUP used Growl! CHIMCHAR's Attack fell! \n",
      "Turn 11: CHIMCHAR used Scratch! PIPLUP used Pound! \n",
      "Turn 12: CHIMCHAR used Scratch! PIPLUP used Growl! CHIMCHAR's Attack won't go any lower! \n",
      "Turn 13: CHIMCHAR used Scratch! PIPLUP used Pound! \n",
      "Turn 14: CHIMCHAR used Scratch! PIPLUP used Growl! \n",
      "Turn 15: CHIMCHAR used Scratch! PIPLUP fainted! lucas has defeated barry! \n"
     ]
    }
   ],
   "source": [
    "done = False\n",
    "rewards = []\n",
    "start = time.time()\n",
    "max_time = 1 # seconds\n",
    "\n",
    "obs, _ = env.reset()\n",
    "while not done:\n",
    "    action, _states = model.predict(obs, deterministic=True)\n",
    "    obs, reward, terminated, truncated, info = env.step(int(action))\n",
    "    rewards.append(reward)\n",
    "    done = terminated or truncated or (time.time() - start > max_time)\n",
    "end = time.time()\n",
    "\n",
    "print(f'Time taken: {end - start} seconds')\n",
    "print(f'Total rewards: {sum(rewards)}')\n",
    "\n",
    "print('Battle log:')\n",
    "cur_txt_parsed = \"\"\n",
    "for line in env._battle.cur_text:\n",
    "    if re.match(r'Turn \\d+:', line):\n",
    "        cur_txt_parsed += '\\n'\n",
    "    cur_txt_parsed += line\n",
    "    cur_txt_parsed += ' '\n",
    "print(cur_txt_parsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Development debugging log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell above keeps giving errors:\n",
    "> ```\n",
    "> File d:\\Users\\luc\\anaconda3\\envs\\deth\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\dummy_vec_env.py:110, in DummyVecEnv._save_obs(self, env_idx, obs)\n",
    ">     108     self.buf_obs[key][env_idx] = obs\n",
    ">     109 else:\n",
    "> --> 110     self.buf_obs[key][env_idx] = obs[key]\n",
    "> \n",
    "> OverflowError: int too big to convert\n",
    "> ```\n",
    "\n",
    "And this one:\n",
    "> ```\n",
    "> File d:\\Users\\luc\\anaconda3\\envs\\deth\\Lib\\site-packages\\stable_baselines3\\common\\preprocessing.py:125, in preprocess_obs(obs, observation_space, normalize_images)\n",
    ">     121     return obs.float()\n",
    ">     123 elif isinstance(observation_space, spaces.Discrete):\n",
    ">     124     # One hot encoding and convert to float to avoid errors\n",
    "> --> 125     return F.one_hot(obs.long(), num_classes=int(observation_space.n)).float()\n",
    ">     127 elif isinstance(observation_space, spaces.MultiDiscrete):\n",
    ">     128     # Tensor concatenation of one hot encodings of each Categorical sub-space\n",
    ">     129     return th.cat(\n",
    ">     130         [\n",
    ">     131             F.one_hot(obs_.long(), num_classes=int(observation_space.nvec[idx])).float()\n",
    ">    (...)\n",
    ">     134         dim=-1,\n",
    ">     135     ).view(obs.shape[0], sum(observation_space.nvec))\n",
    "> \n",
    "> RuntimeError: Class values must be smaller than num_classes.\n",
    "> ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `RuntimeError: Class values must be smaller than num_classes.`\n",
    "\n",
    "As it turned out, I setup the observation spaces completly wrong. Essentially: all discrete spaces had a faulty `n` and `start` value. I rewrote the code for creating the observation spaces and the error was resolved. I also added sanity checks for each space.\n",
    "\n",
    "I then ran the following code to check if the environment is set up correctly:\n",
    "> ```py\n",
    "> from stable_baselines3.common.env_checker import check_env\n",
    "> env = StarterBattleEnvironment()\n",
    "> check_env(env)\n",
    "> ```\n",
    "\n",
    "Which it turned out, it wasnt. The about gave me the output:\n",
    "> ```\n",
    "> UserWarning: Discrete observation space (key='agent_pokemon1_attack') with a non-zero start (start=51) is not supported by Stable-Baselines3. You can use a wrapper or update your observation space.\n",
    "> ```\n",
    "\n",
    "It seemed weird to me that even tough the env is wrapper in a dummyvecenv by stable baselines, the error persists. Regardless, I will try to fix the error by setting the `start` value to 0 for all discrete spaces.\n",
    "\n",
    "##### Solution\n",
    "\n",
    "I heavily reduced the state space to make it more simple, as after 4 days of debugging I still could not get the environment to work. See the [editors note](#EDITORS-NOTE) for more information. Regardless, it works now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `OverflowError: int too big to convert`\n",
    "\n",
    "After printing the some info of the battle instance, it became obvious why the overflow error occurs:\n",
    "> ```py\n",
    "> turtwig\n",
    "> falty_pokemon = env._battle.t1.poke_list[0]\n",
    "> print(falty_pokemon.name)\n",
    "> print(falty_pokemon.stats_actual)\n",
    "> print(falty_pokemon.stats_effective)\n",
    "> print(falty_pokemon.stat_stages)\n",
    "> print(len([ i for i in env._battle.cur_text if 'growl' in i.lower() or 'withdraw' in i.lower() ]))\n",
    "> ```\n",
    "\n",
    "**Output:**\n",
    "> ```\n",
    "> turtwig\n",
    "> [55, 1, 140319401438009622528, 45, 55, 31]\n",
    "> [55, 1, 140319401438009622528, 45, 55, 31]\n",
    "> [0, -6, 6, 0, 0, 0]\n",
    "> 24\n",
    "> ```\n",
    "\n",
    "To summerize the above:\n",
    "- The agent and NPC used stat changing moves (like growl and withdraw) 22 times total.\n",
    "- This resulted in the stats of turtwig chaning\n",
    "    - The attack stat was lowered by 6 stages\n",
    "    - The defence stat was raised by 6 stages\n",
    "\n",
    "This indicated to me that something was wrong with the simulation package I was using. After some debugging I found the fault to reside in `Pokemon.calculate_stats_effective` method. Each time I ran the method on the faulty pokemon instance it essentially quadrupled the defense stat.\n",
    "\n",
    "```\n",
    "falty_pokemon.calculate_stats_effective()\n",
    "[55, 1, 561277605752038490112, 45, 55, 31]\n",
    "```\n",
    "\n",
    "I created an issue on the github repo of the package: https://github.com/hiimvincent/poke-battle-sim/issues/5\n",
    "\n",
    "---\n",
    "##### Solution\n",
    "\n",
    "I found a [fork of the package](https://github.com/thomas18F/pykemon) that fixed the issue (along with some other issues). I uninstalled the package and installed the forked version."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training summery\n",
    "\n",
    "I trained the model whilst tweaking 2 hyperparameters:\n",
    "- `exploration_fraction`: The fraction of the total number of steps during which the exploration rate is annealed.\n",
    "- `total_timesteps`: The total number of steps to train the model.\n",
    "\n",
    "The first 2 itterations I used the default value for exploration fraction (0.1) and a total of tenthousand timesteps. The second itteration I increased the exploration fraction 0.2 and kept the timesteps the same. The results of this are as followes:\n",
    "\n",
    "![First and second itterations](./initial_pokemon_battleing_agent/tb_itterations_1_and_2.png)\n",
    "\n",
    "The results seemed to be to noisy, plus the model was not performing very well. The mean episode reward was way bellow what I wanted it to be. The increase in exploration fraction did not seem to have any effect. So I thought: what if I further increase the exploration fraction whilst also increasing the total timesteps? The results of this are as followes:\n",
    "\n",
    "![Third and fourth itterations](./initial_pokemon_battleing_agent/tb_itterations_3_and_4.png)\n",
    "\n",
    "These results are with an exploration fraction of 0.5 and a total of onehundered thousand timesteps, which took about 3.3 minutes on my CPU (Ryzen 9 7900X). The results are much better then the previous itterations: the mean episode reward is still quite volatile, but it is much higher then before plus it has a clear upward trend. The model seems to be learning, but it is still not performing as well as I would like it to. \n",
    "\n",
    "So for my last experiment I increased the total timesteps to 1 million and keeping the exploration fraction at 0.5. The results of this are as followes:\n",
    "![Fifth and final itteration](./initial_pokemon_battleing_agent/tb_itterations_5.png)\n",
    "\n",
    "This took 35 minutes, again on my CPU, and seems to indicate a linear time growth for training dependend on the total timesteps. The results are much better then the previous itterations: the mean episode reward is still somewhat volatile, but it is much higher then before plus it avarages out to a higher value, especially towards the end of the training session (meaning its exploitation work pretty good)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Based Approach (...)\n",
    "\n",
    "TODO research model based approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: implement model based stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training The Agents\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "The DQN model seems succesfull in learning to do the starter battle. It learns not to perform invalid actions and evaluating the decision making after training shows the agent picks good moves given the state. Its wel known within the pokemon community that the starter battle is not the most plannable battle: it is often simply not possible to win the battle with the starter pokemon. Thats simply because of the nature of the battle. So its perfectly valid that even the best trained agent will not be able to win the battle.\n",
    "\n",
    "All in all, the model is not perfect, but it is a good starting point for further development.\n",
    "\n",
    "What also turned out to be a success is the environment. It provides a good basis for future development and is easy to work with. The only downside is that the state space is quite small given that it only includes starter battle information.\n",
    "\n",
    "### What I learned\n",
    "I learned alot from this experiment:\n",
    "- How to create a proper environment\n",
    "- What states are, how to define them and why certain models can/can not work with them\n",
    "- How a DQN model works and how to train it\n",
    "- How to log data for analysis\n",
    "- How to evaluate the agents decision making\n",
    "- How to evaluate the correctness of an environment\n",
    "- How to test different aspects of a RL problem\n",
    "\n",
    "### Future Work\n",
    "\n",
    "The following topics would be interesting to explore in future experiments:\n",
    "- It might be nice to look into why tensor flow does not recognize my GPU. This could speed up training times.\n",
    "- Expand the environment to include more battles\n",
    "    - This entails increasing the state/action space\n",
    "    - I would also need to look into team building and how to do that properly\n",
    "    - Perhaps it would be cool to train a model on team building as well\n",
    "- Research gen4 ai and implement it the environment to make the NPC more realistic"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deth",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
